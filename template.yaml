---
# Source: sa-final-project/charts/booking-svc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: booking-svc-release-name
  labels:
    helm.sh/chart: booking-svc-0.1.0
    app.kubernetes.io/name: booking-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/email-svc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: email-svc-release-name
  labels:
    helm.sh/chart: email-svc-0.1.0
    app.kubernetes.io/name: email-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/kafka/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-14.9.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
automountServiceAccountToken: true
---
# Source: sa-final-project/charts/mongodb/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-mongodb
  namespace: "default"
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
secrets:
  - name: release-name-mongodb
automountServiceAccountToken: true
---
# Source: sa-final-project/charts/mysql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-mysql
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
automountServiceAccountToken: true
secrets:
  - name: release-name-mysql
---
# Source: sa-final-project/charts/payment-svc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: payment-svc-release-name
  labels:
    helm.sh/chart: payment-svc-0.1.0
    app.kubernetes.io/name: payment-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/redis/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/review-svc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: review-svc-release-name
  labels:
    helm.sh/chart: review-svc-0.1.0
    app.kubernetes.io/name: review-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/vehicle-svc/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: vehicle-svc-release-name

  labels:
    helm.sh/chart: vehicle-svc-0.1.0
    app.kubernetes.io/name: vehicle-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/zipkin/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: zipkin-release-name
  labels:
    helm.sh/chart: zipkin-0.1.0
    app.kubernetes.io/name: zipkin
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: sa-final-project/charts/mongodb/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
type: Opaque
data:
  mongodb-root-password: "R25oc2lwb1dIYTFCMjlENWpGV15UVGNVOGdZdFBnN15HU3Btbw=="
---
# Source: sa-final-project/charts/mysql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-mysql
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  mysql-root-password: "dTMyaXV3ZXVpdXdla2o="
  mysql-password: "aFBTMlR0bjNwTg=="
---
# Source: sa-final-project/templates/jwt-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-jwt-secrets-1
data:
  JWT_PREFIX: NjI1NkIzRTVDRkMyQzk5Mw==
  JWT_SECRET: QEBUbDhRbkZZUzJXJkBLSmtCOWkzQyp0aHdIWCFtUFcxSjBORzJrWjVsNlNmNmo3JiE=
  JWT_ISSUER: ZWR1Lm1pdS5jczU5MA==
---
# Source: sa-final-project/templates/mongo-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-mongo-secrets-1
data:
  MONGODB_USERNAME: cm9vdA==
  MONGODB_PASSWORD: R25oc2lwb1dIYTFCMjlENWpGV15UVGNVOGdZdFBnN15HU3Btbw==
---
# Source: sa-final-project/templates/mysql-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-mysql-secrets-1
data:
  MYSQL_PASSWORD: dTMyaXV3ZXVpdXdla2o=
  MYSQL_USER: cm9vdA==
---
# Source: sa-final-project/charts/auth-svc/templates/auth-mysql-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-auth-mysql-config-1
data:
  MYSQL_DB_NAME: AuthDB
---
# Source: sa-final-project/charts/booking-svc/templates/booking-svc-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-booking-svc-config-1
data:
  MYSQL_DB_NAME: BookingDB
---
# Source: sa-final-project/charts/kafka/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-kafka-scripts
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-14.9.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  setup.sh: |-
    #!/bin/bash

    ID="${MY_POD_NAME#"release-name-kafka-"}"
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        export KAFKA_CFG_BROKER_ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
    else
        export KAFKA_CFG_BROKER_ID="$((ID + 0))"
    fi

    exec /entrypoint.sh /run.sh
---
# Source: sa-final-project/charts/mongodb/templates/common-scripts-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mongodb-common-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
data:
  startup-probe.sh: |
    #!/bin/bash
    mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true$'
  readiness-probe.sh: |
    #!/bin/bash
    # Run the proper check depending on the version
    [[ $(mongod -version | grep "db version") =~ ([0-9]+\.[0-9]+\.[0-9]+) ]] && VERSION=${BASH_REMATCH[1]}
    . /opt/bitnami/scripts/libversion.sh
    VERSION_MAJOR="$(get_sematic_version "$VERSION" 1)"
    VERSION_MINOR="$(get_sematic_version "$VERSION" 2)"
    VERSION_PATCH="$(get_sematic_version "$VERSION" 3)"
    if [[ ( "$VERSION_MAJOR" -ge 5 ) || ( "$VERSION_MAJOR" -ge 4 && "$VERSION_MINOR" -ge 4 && "$VERSION_PATCH" -ge 2 ) ]]; then
        mongosh $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true$'
    else
        mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.isMaster().ismaster || db.isMaster().secondary' | grep -q 'true$'
    fi
  ping-mongodb.sh: |
    #!/bin/bash
    mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval "db.adminCommand('ping')"
---
# Source: sa-final-project/charts/mysql/templates/primary/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mysql
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
data:
  my.cnf: |-
    [mysqld]
    default_authentication_plugin=mysql_native_password
    skip-name-resolve
    explicit_defaults_for_timestamp
    basedir=/opt/bitnami/mysql
    plugin_dir=/opt/bitnami/mysql/lib/plugin
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    datadir=/bitnami/mysql/data
    tmpdir=/opt/bitnami/mysql/tmp
    max_allowed_packet=16M
    bind-address=*
    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
    log-error=/opt/bitnami/mysql/logs/mysqld.log
    character-set-server=UTF8
    collation-server=utf8_general_ci
    slow_query_log=0
    slow_query_log_file=/opt/bitnami/mysql/logs/mysqld.log
    long_query_time=10.0
    
    [client]
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    default-character-set=UTF8
    plugin_dir=/opt/bitnami/mysql/lib/plugin
    
    [manager]
    port=3306
    socket=/opt/bitnami/mysql/tmp/mysql.sock
    pid-file=/opt/bitnami/mysql/tmp/mysqld.pid
---
# Source: sa-final-project/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    slave-read-only yes
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: sa-final-project/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: sa-final-project/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
  start-replica.sh: |
    #!/bin/bash

    get_port() {
        hostname="$1"
        type="$2"

        port_var=$(echo "${hostname^^}_SERVICE_PORT_$type" | sed "s/-/_/g")
        port=${!port_var}

        if [ -z "$port" ]; then
            case $type in
                "SENTINEL")
                    echo 26379
                    ;;
                "REDIS")
                    echo 6379
                    ;;
            esac
        else
            echo $port
        fi
    }

    get_full_hostname() {
        hostname="$1"
        echo "${hostname}.${HEADLESS_SERVICE}"
    }

    REDISPORT=$(get_port "$HOSTNAME" "REDIS")

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    if [[ ! -f /opt/bitnami/redis/etc/replica.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/replica.conf /opt/bitnami/redis/etc/replica.conf
    fi
    if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi

    echo "" >> /opt/bitnami/redis/etc/replica.conf
    echo "replica-announce-port $REDISPORT" >> /opt/bitnami/redis/etc/replica.conf
    echo "replica-announce-ip $(get_full_hostname "$HOSTNAME")" >> /opt/bitnami/redis/etc/replica.conf
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--slaveof" "${REDIS_MASTER_HOST}" "${REDIS_MASTER_PORT_NUMBER}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/replica.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: sa-final-project/templates/kafka-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-kafka-config-1
data:
  KAFKA_SERVER_URL: release-name-kafka:9092
---
# Source: sa-final-project/templates/mongodb-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mongodb-config-1
data:
  MONGODB_HOST: release-name-mongodb
  MONGODB_PORT: "27017"
---
# Source: sa-final-project/templates/mysql-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-mysql-config-1
data:
  MYSQL_DB_HOST: release-name-mysql:3306
  APP_PROFILE: prod
---
# Source: sa-final-project/templates/profile-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-profile-config-1
data:
  APP_PROFILE: prod
  SPRING_PROFILES_ACTIVE: prod
---
# Source: sa-final-project/templates/redis-config
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-config-1
data:
  REDIS_HOST: release-name-redis-master
  REDIS_PORT: "6379"
---
# Source: sa-final-project/templates/services-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-services-config-1
data:
  VEHICLE_SERVICE: vehicle-svc-release-name/api/vehicles
  AUTH_SERVICE: auth-svc-release-name/api/auth
  BOOKING_SERVICE:  booking-svc-release-name/api/bookings
  EMAIL_SERVICE: email-svc-release-name/api/notifications
  PAYMENT_SERVICE: payment-svc-release-name/api/payments
  REVIEW_SERVICE: review-svc-release-name/api/reviews
---
# Source: sa-final-project/templates/zipkin-config.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-zipkin-config-1
data:
  ZIPKIN_SERVER_URL: http://zipkin-release-name:9411
---
# Source: sa-final-project/charts/mongodb/templates/standalone/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-mongodb
  namespace: "default"
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "8Gi"
---
# Source: sa-final-project/charts/auth-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: auth-svc-release-name
  labels:
    helm.sh/chart: auth-svc-0.1.0
    app.kubernetes.io/name: auth-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8088
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: auth-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/booking-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: booking-svc-release-name
  labels:
    helm.sh/chart: booking-svc-0.1.0
    app.kubernetes.io/name: booking-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: booking-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/email-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: email-svc-release-name
  labels:
    helm.sh/chart: email-svc-0.1.0
    app.kubernetes.io/name: email-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: email-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/kafka/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper-headless
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.5.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:

    - name: tcp-client
      port: 2181
      targetPort: client


    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: sa-final-project/charts/kafka/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.5.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  ports:

    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null


    - name: follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: sa-final-project/charts/kafka/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-kafka-headless
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-14.9.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
    - name: tcp-internal
      port: 9093
      protocol: TCP
      targetPort: kafka-internal
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: kafka
---
# Source: sa-final-project/charts/kafka/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-14.9.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
      nodePort: null
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: kafka
---
# Source: sa-final-project/charts/mongodb/templates/standalone/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-mongodb
  namespace: "default"
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: "mongodb"
      port: 27017
      targetPort: mongodb
      nodePort: null
  selector:
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: mongodb
---
# Source: sa-final-project/charts/mysql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-mysql-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: mysql
      port: 3306
      targetPort: mysql
  selector:
    app.kubernetes.io/name: mysql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: sa-final-project/charts/mysql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-mysql
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: mysql
      port: 3306
      protocol: TCP
      targetPort: mysql
      nodePort: null
  selector:
    app.kubernetes.io/name: mysql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: sa-final-project/charts/payment-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: payment-svc-release-name
  labels:
    helm.sh/chart: payment-svc-0.1.0
    app.kubernetes.io/name: payment-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: payment-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP

  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: master
---
# Source: sa-final-project/charts/redis/templates/replicas/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-replicas
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: replica
spec:
  type: ClusterIP
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: replica
---
# Source: sa-final-project/charts/review-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: review-svc-release-name
  labels:
    helm.sh/chart: review-svc-0.1.0
    app.kubernetes.io/name: review-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: review-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/vehicle-svc/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: vehicle-svc-release-name

  labels:
    helm.sh/chart: vehicle-svc-0.1.0
    app.kubernetes.io/name: vehicle-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: vehicle-svc
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/zipkin/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: zipkin-release-name
  labels:
    helm.sh/chart: zipkin-0.1.0
    app.kubernetes.io/name: zipkin
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9411
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: zipkin
    app.kubernetes.io/instance: release-name
---
# Source: sa-final-project/charts/auth-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-svc-release-name
  labels:
    helm.sh/chart: auth-svc-0.1.0
    app.kubernetes.io/name: auth-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: auth-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: auth-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: default
      securityContext:
        {}
      containers:
        - name: auth-svc
          securityContext:
            {}
          image: "ghcr.io/rust42/sa-user-service:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8088
              protocol: TCP
          livenessProbe:
            httpGet:
              path:  /
              port: 8088
            initialDelaySeconds: 60
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path:  /
              port: 8088
            initialDelaySeconds: 60
            periodSeconds: 60
          envFrom:
            - secretRef:
                name: release-name-jwt-secrets-1
            - secretRef:
                name: release-name-mysql-secrets-1
            - configMapRef:
                name: release-name-mysql-config-1
            - configMapRef:
                name: release-name-auth-mysql-config-1
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/booking-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: booking-svc-release-name
  labels:
    helm.sh/chart: booking-svc-0.1.0
    app.kubernetes.io/name: booking-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: booking-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: booking-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: booking-svc-release-name
      securityContext:
        {}
      containers:
        - name: booking-svc
          securityContext:
            {}
          image: "ghcr.io/devbinod/sa-booking-detail-service:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          envFrom:
            - secretRef:
                name: release-name-jwt-secrets-1
            - secretRef:
                name: release-name-mysql-secrets-1
            - configMapRef:
                name: release-name-mysql-config-1
            - configMapRef:
                name: release-name-booking-svc-config-1
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-services-config-1
            - configMapRef:
                name: release-name-kafka-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/email-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: email-svc-release-name
  labels:
    helm.sh/chart: email-svc-0.1.0
    app.kubernetes.io/name: email-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: email-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: email-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: email-svc-release-name
      securityContext:
        {}
      containers:
        - name: email-svc
          securityContext:
            {}
          image: "ghcr.io/devbinod/email-notification:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          envFrom:
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
            - configMapRef:
                name: release-name-kafka-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/mongodb/templates/standalone/dep-sts.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-mongodb
  namespace: "default"
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-13.1.7
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: mongodb
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: mongodb
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mongodb
        helm.sh/chart: mongodb-13.1.7
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: mongodb
    spec:

      serviceAccountName: release-name-mongodb
      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mongodb
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: mongodb
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      securityContext:
        fsGroup: 1001
        sysctls: []

      containers:
        - name: mongodb
          image: docker.io/bitnami/mongodb:6.0.2-debian-11-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MONGODB_ROOT_USER
              value: "root"
            - name: MONGODB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-mongodb
                  key: mongodb-root-password
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: MONGODB_SYSTEM_LOG_VERBOSITY
              value: "0"
            - name: MONGODB_DISABLE_SYSTEM_LOG
              value: "no"
            - name: MONGODB_DISABLE_JAVASCRIPT
              value: "no"
            - name: MONGODB_ENABLE_JOURNAL
              value: "yes"
            - name: MONGODB_PORT_NUMBER
              value: "27017"
            - name: MONGODB_ENABLE_IPV6
              value: "no"
            - name: MONGODB_ENABLE_DIRECTORY_PER_DB
              value: "no"
          ports:
            - name: mongodb
              containerPort: 27017
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 10
            exec:
              command:
                - /bitnami/scripts/ping-mongodb.sh
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bitnami/scripts/readiness-probe.sh
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: datadir
              mountPath: /bitnami/mongodb
              subPath:
            - name: common-scripts
              mountPath: /bitnami/scripts
      volumes:
        - name: common-scripts
          configMap:
            name: release-name-mongodb-common-scripts
            defaultMode: 0550
        - name: datadir
          persistentVolumeClaim:
            claimName: release-name-mongodb
---
# Source: sa-final-project/charts/payment-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-svc-release-name
  labels:
    helm.sh/chart: payment-svc-0.1.0
    app.kubernetes.io/name: payment-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: payment-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: payment-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: payment-svc-release-name
      securityContext:
        {}
      containers:
        - name: payment-svc
          securityContext:
            {}
          image: "ghcr.io/devbinod/sa-payment-service:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          envFrom:
            - secretRef:
                name: release-name-mongo-secrets-1
            - secretRef:
                name: release-name-jwt-secrets-1
            - configMapRef:
                name: release-name-mongodb-config-1
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-services-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
            - configMapRef:
                name: release-name-kafka-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/review-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: review-svc-release-name
  labels:
    helm.sh/chart: review-svc-0.1.0
    app.kubernetes.io/name: review-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: review-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: review-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: review-svc-release-name
      securityContext:
        {}
      containers:
        - name: review-svc
          securityContext:
            {}
          image: "ghcr.io/jenish628/safinal-reviewservice:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path:  /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 60
          envFrom:
            - secretRef:
                name: release-name-mongo-secrets-1
            - secretRef:
                name: release-name-jwt-secrets-1
            - configMapRef:
                name: release-name-mongodb-config-1
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
            - configMapRef:
                name: release-name-redis-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/vehicle-svc/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vehicle-svc-release-name

  labels:
    helm.sh/chart: vehicle-svc-0.1.0
    app.kubernetes.io/name: vehicle-svc
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vehicle-svc
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vehicle-svc
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: vehicle-svc-release-name

      securityContext:
        {}
      containers:
        - name: vehicle-svc
          securityContext:
            {}
          image: "ghcr.io/devbinod/sa-vehicle-service:main"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          envFrom:
            - secretRef:
                name: release-name-mongo-secrets-1
            - secretRef:
                name: release-name-jwt-secrets-1
            - configMapRef:
                name: release-name-mongodb-config-1
            - configMapRef:
                name: release-name-profile-config-1
            - configMapRef:
                name: release-name-services-config-1
            - configMapRef:
                name: release-name-zipkin-config-1
          resources:
            {}
---
# Source: sa-final-project/charts/zipkin/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zipkin-release-name
  labels:
    helm.sh/chart: zipkin-0.1.0
    app.kubernetes.io/name: zipkin
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zipkin
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zipkin
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: zipkin-release-name
      securityContext:
        {}
      containers:
        - name: zipkin
          securityContext:
            {}
          image: "ghcr.io/openzipkin/zipkin:latest"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 9411
              protocol: TCP
          livenessProbe:
            httpGet:
              path: "/health"
              port: 9411
          readinessProbe:
            httpGet:
              path: "/health"
              port: 9411
          resources:
            {}
---
# Source: sa-final-project/charts/kafka/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-7.5.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  serviceName: release-name-zookeeper-headless
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: zookeeper
  template:
    metadata:
      name: release-name-zookeeper
      labels:
        app.kubernetes.io/name: zookeeper
        helm.sh/chart: zookeeper-7.5.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:

      serviceAccountName: default
      securityContext:
        fsGroup: 1001
      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: zookeeper
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.7.0-debian-10-r215
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - bash
            - -ec
            - |
              # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
              # check ZOO_SERVER_ID in persistent volume via myid
              # if not present, set based on POD hostname
              if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
                export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
              else
                HOSTNAME=`hostname -s`
                if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
                  ORD=${BASH_REMATCH[2]}
                  export ZOO_SERVER_ID=$((ORD + 1 ))
                else
                  echo "Failed to get index from hostname $HOST"
                  exit 1
                fi
              fi
              exec /entrypoint.sh /run.sh
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_PRE_ALLOC_SIZE
              value: "65536"
            - name: ZOO_SNAPCOUNT
              value: "100000"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: release-name-zookeeper-0.release-name-zookeeper-headless.default.svc.cluster.local:2888:3888::1
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: data
        annotations:
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sa-final-project/charts/kafka/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-kafka
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-14.9.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: kafka
  serviceName: release-name-kafka-headless
  updateStrategy:
    type: "RollingUpdate"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        helm.sh/chart: kafka-14.9.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: kafka
    spec:

      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kafka
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: kafka
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: release-name-kafka
      containers:
        - name: kafka
          image: docker.io/bitnami/kafka:2.8.1-debian-10-r73
          imagePullPolicy: "IfNotPresent"
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_CFG_ZOOKEEPER_CONNECT
              value: "release-name-zookeeper"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
            - name: KAFKA_CFG_LISTENERS
              value: "INTERNAL://:9093,CLIENT://:9092"
            - name: KAFKA_CFG_ADVERTISED_LISTENERS
              value: "INTERNAL://$(MY_POD_NAME).release-name-kafka-headless.default.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).release-name-kafka-headless.default.svc.cluster.local:9092"
            - name: ALLOW_PLAINTEXT_LISTENER
              value: "yes"
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_LOG_DIR
              value: "/opt/bitnami/kafka/logs"
            - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
              value: "false"
            - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
              value: "10000"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
              value: "1000"
            - name: KAFKA_CFG_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS
              value: "300000"
            - name: KAFKA_CFG_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_CFG_MESSAGE_MAX_BYTES
              value: "1000012"
            - name: KAFKA_CFG_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_DIRS
              value: "/bitnami/kafka/data"
            - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_CFG_NUM_IO_THREADS
              value: "8"
            - name: KAFKA_CFG_NUM_NETWORK_THREADS
              value: "3"
            - name: KAFKA_CFG_NUM_PARTITIONS
              value: "1"
            - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
              value: "1"
            - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
              value: "104857600"
            - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
            - name: KAFKA_CFG_AUTHORIZER_CLASS_NAME
              value: ""
            - name: KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND
              value: "true"
            - name: KAFKA_CFG_SUPER_USERS
              value: "User:admin"
          ports:
            - name: kafka-client
              containerPort: 9092
            - name: kafka-internal
              containerPort: 9093
          livenessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
            periodSeconds: 10
            successThreshold: 1
          readinessProbe:
            tcpSocket:
              port: kafka-client
            initialDelaySeconds: 5
            timeoutSeconds: 5
            failureThreshold: 6
            periodSeconds: 10
            successThreshold: 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
      volumes:
        - name: scripts
          configMap:
            name: release-name-kafka-scripts
            defaultMode: 0755
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sa-final-project/charts/mysql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-mysql
  namespace: "default"
  labels:
    app.kubernetes.io/name: mysql
    helm.sh/chart: mysql-9.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  podManagementPolicy: ""
  selector:
    matchLabels:
      app.kubernetes.io/name: mysql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  serviceName: release-name-mysql
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/configuration: 5326e0ef374ef14c36d3175f9955195aeaeac259f1222ddbc60cbc240f66547d
      labels:
        app.kubernetes.io/name: mysql
        helm.sh/chart: mysql-9.4.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: release-name-mysql

      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mysql
                    app.kubernetes.io/instance: release-name
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      securityContext:
        fsGroup: 1001
      initContainers:
      containers:
        - name: mysql
          image: docker.io/bitnami/mysql:8.0.31-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-mysql
                  key: mysql-root-password
            - name: MYSQL_DATABASE
              value: "my_database"
          envFrom:
          ports:
            - name: mysql
              containerPort: 3306
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          startupProbe:
            failureThreshold: 10
            initialDelaySeconds: 15
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            exec:
              command:
                - /bin/bash
                - -ec
                - |
                  password_aux="${MYSQL_ROOT_PASSWORD:-}"
                  if [[ -f "${MYSQL_ROOT_PASSWORD_FILE:-}" ]]; then
                      password_aux=$(cat "$MYSQL_ROOT_PASSWORD_FILE")
                  fi
                  mysqladmin status -uroot -p"${password_aux}"
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/mysql
            - name: config
              mountPath: /opt/bitnami/mysql/conf/my.cnf
              subPath: my.cnf
      volumes:
        - name: config
          configMap:
            name: release-name-mysql
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: mysql
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: primary
        annotations:
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sa-final-project/charts/redis/templates/master/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: master
  serviceName: release-name-redis-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-15.7.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: c3ee690259a8897caee1994fb60c2db60107121b2dcea68c5478e6b37f5c6856
        checksum/health: 50819fd188d6a9bbc7a312a5ec19c0141dedcfac202796b79881d81202de41c3
        checksum/scripts: f4487330e725547d0e8e1d87fb5952cd37d73f372dedab0d0e68ad8a30112586
        checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:

      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-redis
      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: master
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:6.2.6-debian-10-r81
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
              subPath:
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sa-final-project/charts/redis/templates/replicas/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-replicas
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-15.7.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: replica
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: replica
  serviceName: release-name-redis-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-15.7.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: replica
      annotations:
        checksum/configmap: c3ee690259a8897caee1994fb60c2db60107121b2dcea68c5478e6b37f5c6856
        checksum/health: 50819fd188d6a9bbc7a312a5ec19c0141dedcfac202796b79881d81202de41c3
        checksum/scripts: f4487330e725547d0e8e1d87fb5952cd37d73f372dedab0d0e68ad8a30112586
        checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:

      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-redis
      affinity:
        podAffinity:

        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: replica
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:

      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:6.2.6-debian-10-r81
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-replica.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: slave
            - name: REDIS_MASTER_HOST
              value: release-name-redis-master-0.release-name-redis-headless.default.svc.cluster.local
            - name: REDIS_MASTER_PORT_NUMBER
              value: "6379"
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local_and_master.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local_and_master.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
              subPath:
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: replica
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: sa-final-project/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sa-final-project-release-name
  labels:
    helm.sh/chart: sa-final-project-0.1.0
    app.kubernetes.io/name: sa-final-project
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    ingress.kubernetes.io/enable-cors: "true"
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/cors-allow-headers: Content-Type
    nginx.ingress.kubernetes.io/cors-allow-methods: POST, GET, OPTIONS
    nginx.ingress.kubernetes.io/cors-allow-origin: http://rent-now.s3-website.us-east-2.amazonaws.com
spec:
  rules:
    - host:
      http:
        paths:
          - backend:
              service:
                name: auth-svc-release-name
                port:
                  number: 80
            path: /api/auth
            pathType: Prefix
          - backend:
              service:
                name: vehicle-svc-release-name
                port:
                  number: 80
            path: /api/vehicles
            pathType: Prefix
          - backend:
              service:
                name: booking-svc-release-name
                port:
                  number: 80
            path: /api/bookings
            pathType: Prefix

          - backend:
              service:
                name: zipkin-release-name
                port:
                  number: 9411
            path: /zipkin
            pathType: Prefix

          - backend:
              service:
                name: email-svc-release-name
                port:
                  number: 80
            path: /api/notifications
            pathType: Prefix

          - backend:
              service:
                name: review-svc-release-name
                port:
                  number: 80
            path: /api/reviews
            pathType: Prefix
          - backend:
              service:
                name: payment-svc-release-name
                port:
                  number: 80
            path: /api/payments
            pathType: Prefix
